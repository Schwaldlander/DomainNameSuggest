{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhhJy69+i3K2S/5jEOLSeZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Schwaldlander/DomainNameSuggest/blob/main/model_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates intuitively the outputs of the model.\n",
        "\n",
        " Domain Suggestion Demo (Colab)\n",
        " ===========================\n",
        " - Loads base model + optional LoRA adapter\n",
        " - Generates strict-JSON suggestions for a given brief\n",
        " - Runs spec checks: length / TLD / digits / hyphen / ASCII\n",
        " - Displays a clean preview table\n",
        "\n",
        " Tip:\n",
        " Set ADAPTER=None to run the raw base model\n",
        "  Set IMPROVED_ADAPTER to compare two checkpoints"
      ],
      "metadata": {
        "id": "LjF44hXEvPNf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_1loHeyvA6i"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "\n",
        "\n",
        "!pip -q install \"transformers>=4.43\" \"peft>=0.12\" \"bitsandbytes>=0.43\" pandas sentencepiece\n",
        "\n",
        "import json, re, os, torch, pandas as pd\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "# --------------------------\n",
        "# Config: model + adapters\n",
        "# --------------------------\n",
        "BASE_MODEL = \"Qwen/Qwen2.5-3B-Instruct\"  # change if needed\n",
        "\n",
        "# Put your paths here (or None to skip)\n",
        "ADAPTER = \"/content/checkpoints/baseline_qlora_fixed\"  # e.g., your baseline LoRA\n",
        "IMPROVED_ADAPTER = \"/content/checkpoints/dpo_v1\"       # e.g., improved LoRA\n",
        "# IMPROVED_ADAPTER = None\n",
        "\n",
        "# Decoding params\n",
        "MAX_NEW_TOKENS = 380\n",
        "TEMPERATURE = 0.6\n",
        "TOP_P = 0.9\n",
        "DO_SAMPLE = True\n",
        "\n",
        "# --------------------------\n",
        "# Briefs (same dataset schema)\n",
        "# --------------------------\n",
        "job_networking_brief = {\n",
        "    \"brief_id\": \"job_networking_001\",\n",
        "    \"title\": \"Job Networking Platform\",\n",
        "    \"language\": \"en\",\n",
        "    \"script\": \"Latin\",\n",
        "    \"tone\": \"professional, trustworthy, aspirational\",\n",
        "    \"keywords\": [\"jobs\",\"hire\",\"connect\",\"career\",\"talent\",\"work\",\"network\",\"match\",\"growth\"],\n",
        "    \"constraints\": {\n",
        "        \"max_len\": 14,\n",
        "        \"allowed_tlds\": [\".com\",\".io\",\".ai\"],\n",
        "        \"forbid_digits\": True,\n",
        "        \"forbid_hyphens\": True,\n",
        "        \"ascii_only\": True\n",
        "    },\n",
        "    \"notes\": \"SaaS platform for job seekers & recruiters\"\n",
        "}\n",
        "\n",
        "donut_shop_brief = {\n",
        "    \"brief_id\": \"donut_shop_001\",\n",
        "    \"title\": \"Local Donut Shop\",\n",
        "    \"language\": \"en\",\n",
        "    \"script\": \"Latin\",\n",
        "    \"tone\": \"friendly, cozy, welcoming\",\n",
        "    \"keywords\": [\"donut\",\"coffee\",\"sweet\",\"local\"],\n",
        "    \"constraints\": {\n",
        "        \"max_len\": 12,\n",
        "        \"allowed_tlds\": [\".com\",\".shop\",\".cafe\"],\n",
        "        \"forbid_digits\": True,\n",
        "        \"forbid_hyphens\": True,\n",
        "        \"ascii_only\": True\n",
        "    },\n",
        "    \"notes\": \"Neighborhood bakery + cafe\"\n",
        "}\n",
        "\n",
        "# Pick which brief to demo\n",
        "BRIEF = job_networking_brief  # or donut_shop_brief\n",
        "\n",
        "# --------------------------\n",
        "# Utilities\n",
        "# --------------------------\n",
        "def spec_checks(brief: Dict[str, Any], domain: str) -> Tuple[bool, List[str]]:\n",
        "    reasons = []\n",
        "    try:\n",
        "        name = domain.split(\".\")[0]\n",
        "        tld = \".\" + domain.split(\".\")[-1]\n",
        "    except Exception:\n",
        "        return False, [\"parse_failed\"]\n",
        "\n",
        "    max_len = brief[\"constraints\"].get(\"max_len\", 12)\n",
        "    allowed = brief[\"constraints\"].get(\"allowed_tlds\", [])\n",
        "    forbid_digits = brief[\"constraints\"].get(\"forbid_digits\", True)\n",
        "    forbid_hyphens = brief[\"constraints\"].get(\"forbid_hyphens\", True)\n",
        "    ascii_only = brief[\"constraints\"].get(\"ascii_only\", True)\n",
        "\n",
        "    if len(name) > max_len:\n",
        "        reasons.append(\"length_exceeded\")\n",
        "    if forbid_digits and any(ch.isdigit() for ch in name):\n",
        "        reasons.append(\"digits_forbidden\")\n",
        "    if forbid_hyphens and \"-\" in name:\n",
        "        reasons.append(\"hyphen_forbidden\")\n",
        "    if ascii_only and not name.isascii():\n",
        "        reasons.append(\"non_ascii\")\n",
        "    if allowed and tld not in allowed:\n",
        "        reasons.append(\"tld_not_allowed\")\n",
        "\n",
        "    return (len(reasons) == 0), reasons\n",
        "\n",
        "def extract_first_json(text: str) -> Optional[dict]:\n",
        "    # Extract the first top-level JSON object {...}\n",
        "    stack, start = 0, -1\n",
        "    for i, ch in enumerate(text):\n",
        "        if ch == \"{\":\n",
        "            if stack == 0:\n",
        "                start = i\n",
        "            stack += 1\n",
        "        elif ch == \"}\":\n",
        "            stack -= 1\n",
        "            if stack == 0 and start >= 0:\n",
        "                snippet = text[start:i+1]\n",
        "                try:\n",
        "                    return json.loads(snippet)\n",
        "                except Exception:\n",
        "                    return None\n",
        "    return None\n",
        "\n",
        "def build_prompt(brief: Dict[str, Any]) -> str:\n",
        "    sys = \"You generate brand-safe domain suggestions and strictly refuse unsafe requests. Output strict JSON only.\"\n",
        "    user = f\"\"\"[BRIEF]\n",
        "title: {brief['title']}\n",
        "language: {brief.get('language','en')}\n",
        "tone: {brief.get('tone','')}\n",
        "keywords: {', '.join(brief.get('keywords', []))}\n",
        "constraints:\n",
        "  max_len: {brief['constraints'].get('max_len')}\n",
        "  allowed_tlds: {', '.join(brief['constraints'].get('allowed_tlds', []))}\n",
        "  forbid_digits: {brief['constraints'].get('forbid_digits')}\n",
        "  forbid_hyphens: {brief['constraints'].get('forbid_hyphens')}\n",
        "  ascii_only: {brief['constraints'].get('ascii_only')}\n",
        "\"\"\"\n",
        "    return f\"<|im_start|>system\\n{sys}\\n<|im_end|>\\n<|im_start|>user\\n{user}\\n<|im_end|>\\n<|im_start|>assistant\\n\"\n",
        "\n",
        "def load_model(base_model: str, adapter_dir: Optional[str] = None):\n",
        "    bnb_cfg = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    tok = AutoTokenizer.from_pretrained(base_model, use_fast=True)\n",
        "    if tok.pad_token_id is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model,\n",
        "        quantization_config=bnb_cfg,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.bfloat16\n",
        "    )\n",
        "    model.eval()\n",
        "\n",
        "    if adapter_dir and os.path.isdir(adapter_dir):\n",
        "        try:\n",
        "            model = PeftModel.from_pretrained(model, adapter_dir, is_trainable=False)\n",
        "            print(f\"Loaded LoRA adapter from: {adapter_dir}\")\n",
        "        except Exception as e:\n",
        "            print(\"Warning: could not load adapter:\", e)\n",
        "\n",
        "    return tok, model\n",
        "\n",
        "def generate_json(tok, model, brief: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    prompt = build_prompt(brief)\n",
        "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=MAX_NEW_TOKENS,\n",
        "            do_sample=DO_SAMPLE,\n",
        "            temperature=TEMPERATURE,\n",
        "            top_p=TOP_P,\n",
        "            eos_token_id=tok.eos_token_id\n",
        "        )\n",
        "    text = tok.decode(out_ids[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=False)\n",
        "    obj = extract_first_json(text)\n",
        "    if obj is None:\n",
        "        return {\"error\": \"parse_error\", \"raw\": text[:600]}\n",
        "    return obj\n",
        "\n",
        "def normalize_output(obj: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Returns a list of suggestion records:\n",
        "    [{\"domain\":..., \"rationale\":..., \"spec_ok\":bool, \"spec_reasons\":[...]}, ...]\n",
        "    \"\"\"\n",
        "    suggestions = obj.get(\"suggestions\", [])\n",
        "    rows = []\n",
        "    for s in suggestions:\n",
        "        if not isinstance(s, dict):\n",
        "            continue\n",
        "        domain = s.get(\"domain\")\n",
        "        rationale = s.get(\"rationale\", \"\")\n",
        "        if isinstance(domain, str):\n",
        "            ok, reasons = spec_checks(BRIEF, domain)\n",
        "            rows.append({\n",
        "                \"domain\": domain,\n",
        "                \"rationale\": rationale,\n",
        "                \"spec_ok\": ok,\n",
        "                \"spec_reasons\": reasons\n",
        "            })\n",
        "    return rows\n",
        "\n",
        "def show_table(rows: List[Dict[str, Any]], title: str):\n",
        "    if not rows:\n",
        "        print(title, \"— (no suggestions)\")\n",
        "        return\n",
        "    df = pd.DataFrame(rows)\n",
        "    # sort: spec_ok first, then length\n",
        "    df[\"name_len\"] = df[\"domain\"].apply(lambda d: len(d.split(\".\")[0]) if isinstance(d,str) else 0)\n",
        "    df = df.sort_values(by=[\"spec_ok\",\"name_len\"], ascending=[False, True]).drop(columns=[\"name_len\"])\n",
        "    print(title)\n",
        "    display(df)\n",
        "\n",
        "# --------------------------\n",
        "# Run: single model demo\n",
        "# --------------------------\n",
        "tok, model = load_model(BASE_MODEL, ADAPTER)\n",
        "out = generate_json(tok, model, BRIEF)\n",
        "rows = normalize_output(out)\n",
        "show_table(rows, title=f\"Suggestions — {'adapter: '+ADAPTER if ADAPTER else 'base model'}\")\n",
        "\n",
        "# --------------------------\n",
        "# Optional: compare improved adapter\n",
        "# --------------------------\n",
        "if IMPROVED_ADAPTER:\n",
        "    tok2, model2 = load_model(BASE_MODEL, IMPROVED_ADAPTER)\n",
        "    out2 = generate_json(tok2, model2, BRIEF)\n",
        "    rows2 = normalize_output(out2)\n",
        "    show_table(rows2, title=f\"Suggestions — improved adapter: {IMPROVED_ADAPTER}\")\n",
        "\n",
        "    # Quick side-by-side unique domains (spec_ok only)\n",
        "    s1 = [r[\"domain\"] for r in rows if r[\"spec_ok\"]]\n",
        "    s2 = [r[\"domain\"] for r in rows2 if r[\"spec_ok\"]]\n",
        "    print(\"\\nOverlap (spec-ok):\", set(s1) & set(s2))\n",
        "    print(\"Baseline-only:\", set(s1) - set(s2))\n",
        "    print(\"Improved-only:\", set(s2) - set(s1))\n"
      ]
    }
  ]
}